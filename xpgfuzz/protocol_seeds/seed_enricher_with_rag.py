import os
import shutil
import random
import argparse
from dataclasses import dataclass
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from env_config import (
    require_llm_api_key,
    get_llm_base_url,
    get_embedding_base_url,
    get_embedding_model,
)

# ==============================================================================
# æ¨¡å—ä¸€: é…ç½®ä¸æ•°æ®ç»“æ„
# ==============================================================================
_API_KEY = require_llm_api_key()
_LLM_BASE_URL = get_llm_base_url()
_EMBEDDING_BASE_URL = get_embedding_base_url()

@dataclass
class Protocol:
    """ä¸€ä¸ªç”¨äºå°è£…åè®®ä¿¡æ¯çš„æ•°æ®ç±»ï¼Œå®ç°è§£è€¦ã€‚"""
    name: str
    commands: set

# ==============================================================================
# æ¨¡å—äºŒ: æ–‡ä»¶ä¸RAGå·¥å…·
# ==============================================================================

def setup_directories(input_dir: str, output_dir: str):
    """æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œå¹¶åˆ›å»ºæˆ–æ¸…ç©ºè¾“å‡ºç›®å½•ã€‚"""
    print(f"--- æ­£åœ¨å‡†å¤‡ç›®å½• '{input_dir}' -> '{output_dir}' ---")
    if not os.path.exists(input_dir):
        raise FileNotFoundError(f"è¾“å…¥ç›®å½• '{input_dir}' ä¸å­˜åœ¨ã€‚")
    if os.path.exists(output_dir):
        shutil.rmtree(output_dir)
    os.makedirs(output_dir)

def read_seed_file(filepath: str) -> str:
    """è¯»å–ç§å­æ–‡ä»¶çš„å†…å®¹ã€‚"""
    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            return f.read()
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ '{filepath}' æ—¶å‡ºé”™: {e}")
        return None

def save_enriched_seed(output_dir: str, original_filename: str, content: str, variation_index: int):
    """å°†å¢å¼ºåçš„ç§å­ä¿å­˜åˆ°è¾“å‡ºç›®å½•ã€‚"""
    base_name, ext = os.path.splitext(original_filename)
    new_filename = f"enriched_{base_name}_{variation_index}{ext}"
    output_path = os.path.join(output_dir, new_filename)
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
    except Exception as e:
        print(f"  ä¿å­˜æ–‡ä»¶ '{new_filename}' æ—¶å‡ºé”™: {e}")

def setup_retriever(db_path: str, collection_name: str):
    """ã€æ–°ã€‘åˆå§‹åŒ–å¹¶è¿”å›ä¸€ä¸ªRAGæ£€ç´¢å™¨ã€‚"""
    print(f"--- æ­£åœ¨ä» '{db_path}' (collection: '{collection_name}') åŠ è½½å‘é‡æ•°æ®åº“... ---")
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"ChromaDB ç›®å½•ä¸å­˜åœ¨: {db_path}ã€‚")
    emb_kwargs = {"model": get_embedding_model(), "api_key": _API_KEY}
    if _EMBEDDING_BASE_URL:
        emb_kwargs["base_url"] = _EMBEDDING_BASE_URL
    embeddings = OpenAIEmbeddings(**emb_kwargs)
    vectordb = Chroma(
        persist_directory=db_path,
        embedding_function=embeddings,
        collection_name=collection_name
    )
    return vectordb.as_retriever(search_kwargs={'k': 5})

# ==============================================================================
# æ¨¡å—ä¸‰: æ ¸å¿ƒAIæ‰©å……é€»è¾‘ (å·²æ•´åˆRAG)
# ==============================================================================

def analyze_missing_commands(sequence: str, all_commands: set) -> set:
    """åˆ†æåºåˆ—ï¼Œè¿”å›ç¼ºå¤±çš„å‘½ä»¤é›†ã€‚"""
    sequence_lower = sequence.lower()
    present_commands = {cmd for cmd in all_commands if cmd.lower() in sequence_lower}
    return all_commands - present_commands

def enrich_sequence_with_rag(sequence: str, protocol: Protocol, retriever, temperature: float, max_enrich_types: int, model: str) -> str:
    """
    ã€è¿›åŒ–ã€‘ä½¿ç”¨RAGå¢é‡å¼æ‰©å……å•ä¸ªåºåˆ—ã€‚
    """
    missing_commands = analyze_missing_commands(sequence, protocol.commands)
    
    if not missing_commands:
        print("  åºåˆ—å·²åŒ…å«æ‰€æœ‰æŒ‡å®šå‘½ä»¤ï¼Œæ— éœ€æ‰©å……ã€‚")
        return None

    if max_enrich_types > 0 and len(missing_commands) > max_enrich_types:
        commands_to_add = set(random.sample(list(missing_commands), max_enrich_types))
    else:
        commands_to_add = missing_commands

    # --- RAGæ ¸å¿ƒæ­¥éª¤ï¼šä¸ºå¾…æ·»åŠ çš„å‘½ä»¤æ£€ç´¢ä¸Šä¸‹æ–‡ ---
    print(f"  -> RAG: æ­£åœ¨ä¸ºå‘½ä»¤ {commands_to_add} æ£€ç´¢ä¸Šä¸‹æ–‡...")
    context_str = ""
    for cmd in commands_to_add:
        query = f"How to use the {cmd} command in {protocol.name} protocol, including syntax and examples."
        docs = retriever.invoke(query)
        context_str += f"\n--- Documentation for {cmd} ---\n"
        context_str += "\n".join([doc.page_content for doc in docs])
        context_str += "\n"

    # --- å‡çº§Promptï¼Œæ³¨å…¥ä»æ‚¨æ•°æ®åº“ä¸­æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ ---
    prompt_template = """
You are an expert in the {protocol_name} protocol. Your task is to intelligently complete an incomplete message sequence for fuzzing purposes, based on the provided authoritative documentation.

**Authoritative Context from Your Documents:**
{context}

**Analysis:**
The provided sequence is missing several commands. Based on the context, we will focus on inserting the following commands in this step: {commands_to_add_str}

**Task:**
Rewrite the sequence, inserting the specified missing commands in logically correct positions to form a valid and comprehensive conversation.

**Rules:**
1.  Strictly follow the syntax and examples from the provided context.
2.  The final output must be ONLY the raw message sequence.
3.  Do not add any explanations or comments.
4.  Ensure the conversation flow is logical for the {protocol_name} protocol.

**Incomplete Sequence:**
{original_sequence}

**Completed Sequence:**
"""
    prompt = ChatPromptTemplate.from_template(prompt_template)
    llm_kwargs = {"model": model, "temperature": temperature, "api_key": _API_KEY}
    if _LLM_BASE_URL:
        llm_kwargs["base_url"] = _LLM_BASE_URL
    llm = ChatOpenAI(**llm_kwargs)
    enrichment_chain = prompt | llm | StrOutputParser()
    
    enriched_sequence = enrichment_chain.invoke({
        "protocol_name": protocol.name,
        "context": context_str,
        "commands_to_add_str": ", ".join(sorted(list(commands_to_add))),
        "original_sequence": sequence
    })
    
    return enriched_sequence

# ==============================================================================
# æ¨¡å—å››: ä¸»æµç¨‹æ§åˆ¶å™¨ (å·²æ•´åˆRAG)
# ==============================================================================

def main_process(args):
    """
    è‡ªåŠ¨åŒ–å¤„ç†æ•´ä¸ªç›®å½•çš„ç§å­æ–‡ä»¶çš„ä¸»æµç¨‹ã€‚
    """
    command_set = {cmd.strip() for cmd in args.commands.split(',') if cmd.strip()}
    protocol = Protocol(name=args.protocol_name, commands=command_set)

    setup_directories(args.input_dir, args.output_dir)
    
    # ã€æ–°ã€‘åˆå§‹åŒ–RAGæ£€ç´¢å™¨
    retriever = setup_retriever(args.db_dir, args.collection_name)
    
    all_seed_files = [f for f in os.listdir(args.input_dir) if os.path.isfile(os.path.join(args.input_dir, f))]
    
    if not all_seed_files:
        print(f"è­¦å‘Š: è¾“å…¥ç›®å½• '{args.input_dir}' ä¸­æ²¡æœ‰æ‰¾åˆ°ç§å­æ–‡ä»¶ã€‚")
        return

    if args.max_corpus_size > 0 and len(all_seed_files) > args.max_corpus_size:
        seed_files_to_process = random.sample(all_seed_files, args.max_corpus_size)
    else:
        seed_files_to_process = all_seed_files
    
    print(f"\n--- åè®® '{protocol.name}' | å¼€å§‹æ‰¹é‡æ‰©å…… {len(seed_files_to_process)} ä¸ªç§å­æ–‡ä»¶... ---")
    
    total_generated = 0
    for filename in seed_files_to_process:
        filepath = os.path.join(args.input_dir, filename)
        print(f"\nå¤„ç†åŸå§‹ç§å­: {filename}")
        original_content = read_seed_file(filepath)
        if not original_content: continue
        
        generated_for_this_seed = 0
        for i in range(args.variations):
            temp = random.uniform(0.3, 0.8)
            print(f"  -> ç”Ÿæˆå˜ä½“ {i+1}/{args.variations} (temperature={temp:.2f})...")
            
            # ã€æ–°ã€‘è°ƒç”¨å¸¦æœ‰RAGèƒ½åŠ›çš„æ–°å‡½æ•°
            enriched_content = enrich_sequence_with_rag(
                original_content, protocol, retriever, temp, args.max_enrich_types, args.model
            )
            
            if enriched_content and enriched_content.strip() != original_content.strip():
                save_enriched_seed(args.output_dir, filename, enriched_content, i + 1)
                generated_for_this_seed += 1
        
        if generated_for_this_seed > 0:
            print(f"  æˆåŠŸä¸º {filename} ç”Ÿæˆäº† {generated_for_this_seed} ä¸ªæ–°ç§å­ã€‚")
        total_generated += generated_for_this_seed

    print(f"\nğŸ‰ æ‰¹é‡æ‰©å……ä»»åŠ¡å®Œæˆï¼æ€»è®¡ç”Ÿæˆäº† {total_generated} ä¸ªæ–°ç§å­ï¼Œå·²ä¿å­˜è‡³ '{args.output_dir}' ç›®å½•ã€‚")

# ==============================================================================
# è„šæœ¬å…¥å£: å¢åŠ RAGç›¸å…³å‚æ•°
# ==============================================================================

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="[RAGå¢å¼ºç‰ˆ]é€šç”¨åè®®ç§å­ä¸°å¯Œå™¨",
        formatter_class=argparse.RawTextHelpFormatter
    )
    
    # RAGç›¸å…³å‚æ•°
    parser.add_argument("--db-dir", default="./chroma_db_protocols", type=str, help="ChromaDBæŒä¹…åŒ–å­˜å‚¨çš„è·¯å¾„ã€‚")
    parser.add_argument("--collection-name", required=True, type=str, help="ChromaDBä¸­çš„Collectionåç§°ã€‚")
    
    # åŸå§‹å‚æ•°
    parser.add_argument("--protocol-name", required=True, type=str, help="åè®®çš„åç§° (ä¾‹å¦‚ 'Exim SMTP', 'FTP')ã€‚")
    parser.add_argument("--commands", required=True, type=str, help="è¯¥åè®®çš„å‘½ä»¤å…¨é›†ï¼Œç”¨é€—å·åˆ†éš”ã€‚")
    parser.add_argument("--input-dir", default="in", type=str, help="åŒ…å«åŸå§‹ç§å­æ–‡ä»¶çš„è¾“å…¥ç›®å½•ã€‚")
    parser.add_argument("--output-dir", default="out", type=str, help="ç”¨äºå­˜æ”¾ç”Ÿæˆç§å­çš„è¾“å‡ºç›®å½•ã€‚")
    parser.add_argument("--variations", default=5, type=int, help="æ¯ä¸ªåŸå§‹ç§å­è¦ç”Ÿæˆçš„å˜ä½“æ•°é‡ã€‚")
    parser.add_argument("--model", default="gpt-4-turbo", type=str, help="è¦ä½¿ç”¨çš„OpenAIæ¨¡å‹ã€‚")
    parser.add_argument("--max-enrich-types", default=2, type=int, help="å•æ¬¡ä¸°å¯Œæ“ä½œä¸­æœ€å¤šæ·»åŠ çš„å‘½ä»¤ç±»å‹æ•°é‡ã€‚")
    parser.add_argument("--max-corpus-size", default=10, type=int, help="ä»è¾“å…¥ç›®å½•ä¸­æœ€å¤šå¤„ç†çš„ç§å­æ–‡ä»¶æ•°é‡ã€‚")

    args = parser.parse_args()
    main_process(args)