import os
import shutil
import random
import argparse
from dataclasses import dataclass
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from env_config import require_llm_api_key, get_llm_base_url

# ==============================================================================
# æ¨¡å—ä¸€: é…ç½®ä¸æ•°æ®ç»“æ„
# ==============================================================================
# åŠ è½½/æ ¡éªŒç¯å¢ƒå˜é‡ï¼ˆåŒ¿åå‘å¸ƒï¼šä¸åœ¨ä»£ç ä¸­ç¡¬ç¼–ç ä»»ä½• key/base_urlï¼‰
_API_KEY = require_llm_api_key()
_BASE_URL = get_llm_base_url()

@dataclass
class Protocol:
    """ä¸€ä¸ªç”¨äºå°è£…åè®®ä¿¡æ¯çš„æ•°æ®ç±»ï¼Œå®ç°è§£è€¦ã€‚"""
    name: str
    commands: set

# ==============================================================================
# æ¨¡å—äºŒ: æ–‡ä»¶å·¥å…· (æ— å˜åŒ–)
# ==============================================================================

def setup_directories(input_dir: str, output_dir: str):
    """æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œå¹¶åˆ›å»ºæˆ–æ¸…ç©ºè¾“å‡ºç›®å½•ã€‚"""
    print(f"--- æ­£åœ¨å‡†å¤‡ç›®å½• '{input_dir}' -> '{output_dir}' ---")
    if not os.path.exists(input_dir):
        raise FileNotFoundError(f"è¾“å…¥ç›®å½• '{input_dir}' ä¸å­˜åœ¨ã€‚")
    if os.path.exists(output_dir):
        shutil.rmtree(output_dir)
    os.makedirs(output_dir)

def read_seed_file(filepath: str) -> str:
    """è¯»å–ç§å­æ–‡ä»¶çš„å†…å®¹ã€‚"""
    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            return f.read()
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ '{filepath}' æ—¶å‡ºé”™: {e}")
        return None

def save_enriched_seed(output_dir: str, original_filename: str, content: str, variation_index: int):
    """å°†å¢å¼ºåçš„ç§å­ä¿å­˜åˆ°è¾“å‡ºç›®å½•ã€‚"""
    base_name, ext = os.path.splitext(original_filename)
    new_filename = f"enriched_{base_name}_{variation_index}{ext}"
    output_path = os.path.join(output_dir, new_filename)
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
    except Exception as e:
        print(f"  ä¿å­˜æ–‡ä»¶ '{new_filename}' æ—¶å‡ºé”™: {e}")

# ==============================================================================
# æ¨¡å—ä¸‰: æ ¸å¿ƒAIæ‰©å……é€»è¾‘ (å·²è§£è€¦)
# ==============================================================================

def analyze_missing_commands(sequence: str, all_commands: set) -> set:
    """åˆ†æåºåˆ—ï¼Œè¿”å›ç¼ºå¤±çš„å‘½ä»¤é›†ã€‚"""
    sequence_lower = sequence.lower()
    present_commands = {cmd for cmd in all_commands if cmd.lower() in sequence_lower}
    return all_commands - present_commands

def enrich_sequence(sequence: str, protocol: Protocol, temperature: float, max_enrich_types: int, model: str) -> str:
    """
    ä½¿ç”¨LLMå¢é‡å¼æ‰©å……å•ä¸ªåºåˆ—ï¼ˆåè®®é€šç”¨ç‰ˆæœ¬ï¼‰ã€‚
    """
    missing_commands = analyze_missing_commands(sequence, protocol.commands)
    
    if not missing_commands:
        print("  åºåˆ—å·²åŒ…å«æ‰€æœ‰æŒ‡å®šå‘½ä»¤ï¼Œæ— éœ€æ‰©å……ã€‚")
        return None

    if max_enrich_types > 0 and len(missing_commands) > max_enrich_types:
        commands_to_add = set(random.sample(list(missing_commands), max_enrich_types))
    else:
        commands_to_add = missing_commands

    prompt_template = """
You are an expert in the {protocol_name} protocol. Your task is to intelligently complete an incomplete message sequence for fuzzing purposes.

**Analysis:**
The provided sequence is missing several commands. We will focus on inserting the following commands in this step: {commands_to_add_str}

**Task:**
Rewrite the sequence, inserting the specified missing commands in logically correct positions to form a valid and more comprehensive conversation.

**Rules:**
1.  The final output must be ONLY the raw message sequence.
2.  Do not add any explanations or comments.
3.  Ensure the conversation flow is logical for the {protocol_name} protocol.
4.  Use plausible arguments for commands.

**Incomplete Sequence:**
{original_sequence}

**Completed Sequence:**
"""
    prompt = ChatPromptTemplate.from_template(prompt_template)
    llm_kwargs = {"model": model, "temperature": temperature, "api_key": _API_KEY}
    if _BASE_URL:
        llm_kwargs["base_url"] = _BASE_URL
    llm = ChatOpenAI(**llm_kwargs)
    enrichment_chain = prompt | llm | StrOutputParser()
    
    enriched_sequence = enrichment_chain.invoke({
        "protocol_name": protocol.name,
        "commands_to_add_str": ", ".join(sorted(list(commands_to_add))),
        "original_sequence": sequence
    })
    
    return enriched_sequence

# ==============================================================================
# æ¨¡å—å››: ä¸»æµç¨‹æ§åˆ¶å™¨ (å·²è§£è€¦)
# ==============================================================================

def main_process(args):
    """
    è‡ªåŠ¨åŒ–å¤„ç†æ•´ä¸ªç›®å½•çš„ç§å­æ–‡ä»¶çš„ä¸»æµç¨‹ã€‚
    """
    # ä»å‘½ä»¤è¡Œå‚æ•°æ„é€ åè®®å¯¹è±¡
    command_set = {cmd.strip() for cmd in args.commands.split(',') if cmd.strip()}
    protocol = Protocol(name=args.protocol_name, commands=command_set)

    setup_directories(args.input_dir, args.output_dir)
    
    all_seed_files = [f for f in os.listdir(args.input_dir) if os.path.isfile(os.path.join(args.input_dir, f))]
    
    if not all_seed_files:
        print(f"è­¦å‘Š: è¾“å…¥ç›®å½• '{args.input_dir}' ä¸­æ²¡æœ‰æ‰¾åˆ°ç§å­æ–‡ä»¶ã€‚")
        return

    if args.max_corpus_size > 0 and len(all_seed_files) > args.max_corpus_size:
        seed_files_to_process = random.sample(all_seed_files, args.max_corpus_size)
    else:
        seed_files_to_process = all_seed_files
    
    print(f"\n--- åè®® '{protocol.name}' | å¼€å§‹æ‰¹é‡æ‰©å…… {len(seed_files_to_process)} ä¸ªç§å­æ–‡ä»¶... ---")
    
    total_generated = 0
    for filename in seed_files_to_process:
        filepath = os.path.join(args.input_dir, filename)
        print(f"\nå¤„ç†åŸå§‹ç§å­: {filename}")
        original_content = read_seed_file(filepath)
        if not original_content: continue
        
        generated_for_this_seed = 0
        for i in range(args.variations):
            temp = random.uniform(0.3, 0.8)
            print(f"  -> ç”Ÿæˆå˜ä½“ {i+1}/{args.variations} (temperature={temp:.2f})...")
            
            enriched_content = enrich_sequence(
                original_content, protocol, temp, args.max_enrich_types, args.model
            )
            
            if enriched_content and enriched_content.strip() != original_content.strip():
                save_enriched_seed(args.output_dir, filename, enriched_content, i + 1)
                generated_for_this_seed += 1
        
        if generated_for_this_seed > 0:
            print(f"  æˆåŠŸä¸º {filename} ç”Ÿæˆäº† {generated_for_this_seed} ä¸ªæ–°ç§å­ã€‚")
        total_generated += generated_for_this_seed

    print(f"\nğŸ‰ æ‰¹é‡æ‰©å……ä»»åŠ¡å®Œæˆï¼æ€»è®¡ç”Ÿæˆäº† {total_generated} ä¸ªæ–°ç§å­ï¼Œå·²ä¿å­˜è‡³ '{args.output_dir}' ç›®å½•ã€‚")

# ==============================================================================
# è„šæœ¬å…¥å£: ä½¿ç”¨ argparse è¿›è¡Œå‘½ä»¤è¡Œè§£æ
# ==============================================================================

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="é€šç”¨åè®®ç§å­ä¸°å¯Œå™¨ (Generic Protocol Seed Enricher)",
        formatter_class=argparse.RawTextHelpFormatter
    )
    
    parser.add_argument(
        "--protocol-name",
        required=True,
        type=str,
        help="åè®®çš„åç§° (ä¾‹å¦‚ 'Exim SMTP', 'FTP')ï¼Œå°†ç”¨äºAI Promptã€‚"
    )
    parser.add_argument(
        "--commands",
        required=True,
        type=str,
        help="è¯¥åè®®çš„å‘½ä»¤å…¨é›†ï¼Œç”¨é€—å·åˆ†éš” (ä¾‹å¦‚ 'HELO,EHLO,MAIL FROM,...')ã€‚"
    )
    parser.add_argument(
        "--input-dir",
        default="in",
        type=str,
        help="åŒ…å«åŸå§‹ç§å­æ–‡ä»¶çš„è¾“å…¥ç›®å½• (é»˜è®¤: 'in')ã€‚"
    )
    parser.add_argument(
        "--output-dir",
        default="out",
        type=str,
        help="ç”¨äºå­˜æ”¾ç”Ÿæˆç§å­çš„è¾“å‡ºç›®å½• (é»˜è®¤: 'out')ã€‚"
    )
    parser.add_argument(
        "--variations",
        default=20,
        type=int,
        help="æ¯ä¸ªåŸå§‹ç§å­è¦ç”Ÿæˆçš„å˜ä½“æ•°é‡ (é»˜è®¤: 20)ã€‚"
    )
    parser.add_argument(
        "--model",
        default="gpt-4-turbo",
        type=str,
        help="è¦ä½¿ç”¨çš„OpenAIæ¨¡å‹ (é»˜è®¤: 'gpt-4-turbo')ã€‚"
    )
    parser.add_argument(
        "--max-enrich-types",
        default=2,
        type=int,
        help="å•æ¬¡ä¸°å¯Œæ“ä½œä¸­æœ€å¤šæ·»åŠ çš„å‘½ä»¤ç±»å‹æ•°é‡ (0ä¸ºæ— é™åˆ¶, é»˜è®¤: 2)ã€‚"
    )
    parser.add_argument(
        "--max-corpus-size",
        default=10,
        type=int,
        help="ä»è¾“å…¥ç›®å½•ä¸­æœ€å¤šå¤„ç†çš„ç§å­æ–‡ä»¶æ•°é‡ (0ä¸ºæ— é™åˆ¶, é»˜è®¤: 10)ã€‚"
    )

    args = parser.parse_args()
    main_process(args)
